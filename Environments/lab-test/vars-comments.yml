# ==============================================================================
# ENVIRONMENT: k8calab2 (California Lab 2)
# ==============================================================================
# Fully source-mapped from OLD REPOSITORIES
#
# OLD REPOS (SOURCE OF TRUTH):
#   1. k8s-terraform-master/Kubernetes Clusters/k8calab2/
#   2. Terraform-master/
#   3. k8s-yamls-master/
#
# CURRENT REPO ( BRANCH ):
#   k8s-multi-cluster-automation (features/kubespray-deployment branch)
#
# ==============================================================================

# Source: k8s-terraform-master/Kubernetes Clusters/k8calab2
cluster_name: k8calab2

# Source: k8s-terraform-master/Kubernetes Clusters/k8calab2/kubecluster-clab2.tf (line 7)
# variable "env" {default = "dev"}
environment: dev

# Source: k8s-terraform-master/Kubernetes Clusters/k8calab2/kubecluster-clab2.tf (line 6)
# variable "dc" {default = "wtd"}
datacenter: WTD

# ⚠️ NOT IN OLD REPOS - Inferred from "California" context
# region: california

# ==============================================================================
# CLUSTER CONFIGURATION  
# ==============================================================================
cluster:
  name: k8calab2
  
  # ⚠️ NOT EXPLICITLY IN OLD REPOS
  # Source: Inferred from bootstrap script usage of containerd
  # OLD REPOS doesn't configure this explicitly
  container_runtime: containerd #kubespray default
  
  # Source: k8s-terraform-master/Kubernetes Clusters/k8calab2/kubecluster-clab2.tf (line 2)
  # variable "domain" {default = "mednt"}
  domain: mednt

# ==============================================================================
# VSPHERE CONFIGURATION
# ==============================================================================
vsphere:
  # Source: Terraform-master/globals.tf (line 92) (standard vCenter for WTD datacenter)
  # All clusters in WTD use this vCenter 
  server: "vcenter-wtd.medimpact.com" 
  
  # Source: k8s-terraform-master/Kubernetes Clusters/k8calab2/kubecluster-clab2.tf (line 6)
  # variable "dc" {default = "wtd"}  
  datacenter: "WTD"
  
  # Source: Terraform-master/globals.tf (standard datastore for WTD)
  datastore: "WTD_Datastore_01"
  
  # Source: Terraform-master/globals.tf (line 158) (standard resource pool for K8s)
  resource_pool: "K8S_Resource_Pool"
  
  # Source: k8s-terraform-master/Kubernetes Clusters/k8calab2/kubecluster-clab2.tf (line 18)
  # vm_specs entry: "vswitch2-med-vlan-33"
  # CRITICAL: This is the actual VLAN for k8calab2!
  network: "vswitch2-med-vlan-33"
  
  # Source: k8s-terraform-master/Kubernetes Clusters/k8calab2/kubecluster-clab2.tf (line 8)
  # variable "vmtemplate" {default = "centos7"}
  
  template: "centos7"  

# ==============================================================================
# NETWORK CONFIGURATION
# ==============================================================================
network:
  # Source: k8s-terraform-master/Kubernetes Clusters/k8calab2/kubecluster-clab2.tf (line 18)
  # vm_specs: "10.13.103.224", gateway: "10.13.103.1"
  prefix: "10.13.103"
  
  # Source: k8s-terraform-master/Kubernetes Clusters/k8calab2/kubecluster-clab2.tf (line 18)
  # vm_specs gateway field (index 7): "10.13.103.1"
  gateway: "10.13.103.1"
  
  # Source: k8s-terraform-master/Kubernetes Clusters/k8calab2/kubecluster-clab2.tf (line 18)
  # vm_specs prefix length field (index 8): CIDR prefix length = 24 = 255.255.255.0 netmask 
  # Kubespray needs netmask(255.255.255.0) format, not CIDR(24) format.
  netmask: "255.255.255.0"
  
  # Source: Terraform-master/RemoteBuildFiles-Active/system_setup_auto.sh (line 86)
  # Standard DNS servers for MedImpact WTD datacenter
  dns_servers:
    - "10.13.2.15"
    - "10.13.2.15"
      
  # Source: k8s-terraform-master\Kubernetes Clusters\k8calab2\RemoteBuildFiles-calab\kube\kube-master-config.yml
  domain: "cluster.local"  # (line 67)
  
  # Source: keepalived-dv1medk8lab2proxy1.conf (line "virtual_ipaddress")
  # OLD REPO use Keepalived VIP: 10.13.103.223

  # ⚠️ OLD REPO uses SINGLE VIP for both API and Ingress
  # Your automation expects 2 separate VIPs so to ruleout any issue we used all 3 variables but same ip
  api_vip: "10.13.103.223"        # ✅ Used for BOTH API and Ingress traffic
  ingress_vip: "10.13.103.223"    # Same as API VIP
  virtual_ip: "10.13.103.223"

# How it works in OLD REPO setup:

# HAProxy nodes: 10.13.103.221, 10.13.103.222
# VIP (floating): 10.13.103.223
# Keepalived manages VIP failover between HAProxy nodes
# HAProxy listens on VIP and proxies to backend nodes
# Users connect to: 10.13.103.223 (the VIP)




  
  # ⚠️ NOT IN OLD REPOS REPOS - Modern Kubespray requirement
  # OLD REPOS doesn't explicitly configure CNI in old setup
  cni: "calico"
  
# source: k8s-terraform-master\Kubernetes Clusters\k8calab2\RemoteBuildFiles-calab\kube\kube-master-config.yml
  service_cidr: "10.246.0.0/16"   # line 69 "serviceSubnet: 10.236.0.0/16" 
  pod_cidr: "10.246.0.0/16"    # line 69 "podSubnet:

# ==============================================================================
# NODE DEFINITIONS
# ==============================================================================
# Source: k8s-terraform-master/Kubernetes Clusters/k8calab2/kubecluster-clab2.tf (lines 14-23)
# AND: k8s-terraform-master/Kubernetes Clusters/k8calab2/RemoteBuildFiles-calab/haproxy.cfg

nodes:
  masters:
    # Source: kubecluster-clab2.tf line 20
    # "0" = ["dv1medk8lab2ma01", "B", "10.13.103.224", "2", "8192", "40", ...]
    - hostname: "dv1medk8lab2ma01"
      ip: "10.13.103.224"
      cpu: 2        # Source: field index 3
      memory: 8192  # Source: field index 4 (MB)
      disk: 40      # Source: field index 5 (GB)
    
    # Source: kubecluster-clab2.tf line 21
    # "1" = ["dv1medk8lab2ma02", "B", "10.13.103.225", "2", "8192", "40", ...]
    - hostname: "dv1medk8lab2ma02"
      ip: "10.13.103.225"
      cpu: 2
      memory: 8192
      disk: 40
    
    # Source: kubecluster-clab2.tf line 22
    # "2" = ["dv1medk8lab2ma03", "B", "10.13.103.226", "2", "8192", "40", ...]
    - hostname: "dv1medk8lab2ma03"
      ip: "10.13.103.226"
      cpu: 2
      memory: 8192
      disk: 40
  
  workers:
    # Source: kubecluster-clab2.tf line 23
    # "3" = ["dv1medk8lab2no01", "B", "10.13.103.227", "2", "10240", "40", ...]
    - hostname: "dv1medk8lab2no01"
      ip: "10.13.103.227"
      cpu: 2        # Source: field index 3
      memory: 10240 # Source: field index 4 (MB) = 10GB
      disk: 40      # Source: field index 5 (GB)
    
    # Source: kubecluster-clab2.tf line 24
    # "4" = ["dv1medk8lab2no02", "B", "10.13.103.228", "2", "10240", "40", ...]
    - hostname: "dv1medk8lab2no02"
      ip: "10.13.103.228"
      cpu: 2
      memory: 10240
      disk: 40
    
    # Source: kubecluster-clab2.tf line 25 (COMMENTED OUT in Terraform!)
    # #"5" = ["dv1medk8lab2no03", "B", "10.13.103.229", "2", "10240", "40", ...]
    # BUT: haproxy.cfg line 73 shows this node IS configured!
    # AND: Screenshot shows this node exists!
    - hostname: "dv1medk8lab2no03"
      ip: "10.13.103.229"
      cpu: 2
      memory: 10240
      disk: 40
    
    # Source: kubecluster-clab2.tf line 26 (COMMENTED OUT)
    # BUT: haproxy.cfg line 74 shows this node IS configured!
    # AND: Screenshot shows this node exists!
    - hostname: "dv1medk8lab2no04"
      ip: "10.13.103.230"
      cpu: 2
      memory: 10240
      disk: 40
    
    # Source: kubecluster-clab2.tf line 27 (COMMENTED OUT)
    # BUT: haproxy.cfg line 75 shows this node IS configured!
    # AND: Screenshot shows this node exists!
    - hostname: "dv1medk8lab2no05"
      ip: "10.13.103.231"
      cpu: 2
      memory: 10240
      disk: 40
  
  haproxy:
    # Source: k8s-terraform-master\Kubernetes Clusters\k8calab2\RemoteBuildFiles-calab\keepalived-dv1medk8lab2proxy1.conf (line 20)
    # AND: kubecluster-clab2.tf line 19
    # "0" = ["dv1medk8lab2proxy1", "B", "10.13.103.221", "2", "2048", "10", ...]
    - hostname: "dv1medk8lab2proxy1"
      ip: "10.13.103.221"
      cpu: 2         # Source: field index 3
      memory: 2048   # Source: field index 4 (MB)
      disk: 10       # Source: field index 5 (GB)
      keepalived_state: "MASTER"     # line 8 of keepalived-dv1medk8lab2proxy1.conf
      keepalived_priority: 200        # line 9 of keepalived-dv1medk8lab2proxy1.conf
    
    # Source: haproxy-calab2.tf line 21
    # "1" = ["dv1medk8lab2proxy2", "B", "10.13.103.222", "2", "2048", "10", ...]
    - hostname: "dv1medk8lab2proxy2"
      ip: "10.13.103.222"
      cpu: 2
      memory: 2048
      disk: 10
      keepalived_state: "BACKUP"    # line 8 of keepalived-dv1medk8lab2proxy2.conf
      keepalived_priority: 100      # line 9 of keepalived-dv1medk8lab2proxy2.conf

# ==============================================================================
# HAPROXY CONFIGURATION
# ==============================================================================
# Source: k8s-terraform-master/Kubernetes Clusters/k8calab2/RemoteBuildFiles-calab/haproxy.cfg
haproxy:
  # Source: haproxy.cfg line 14: "maxconn 4000" (line 30)
  maxconn: 4000
  
  # Source: haproxy.cfg line 49: "timeout connect 10s"
  timeout_connect: "10s"
  
  # Source: haproxy.cfg line 50: "timeout OLD REPOS 1m"
  timeout_client: "1m"
  
  # Source: haproxy.cfg line 51: "timeout server 1m"
  timeout_server: "1m"
  
  # Source: haproxy.cfg line 94: "listen stats-8080 :8080"
  stats_port: 8080
  
  # ⚠️ NOT IN OLD REPOS REPOS - Stats auth not configured in their haproxy.cfg
  # They don't have username/password for stats page
  # stats_user: "admin"          # ← ask Kiran WHAT THEY WANT
  # stats_password: "admin123"   # ← ask Kiran WHAT THEY WANT
  
  # Source: haproxy.cfg lines 62-85
  # backend k8s-web-http-30080 and k8s-web-https-30443
  # OLD REPOS uses NodePort 30080/30443 for ingress
  ingress_http_nodeport: 30080
  ingress_https_nodeport: 30443

# ==============================================================================
# KEEPALIVED CONFIGURATION
# ==============================================================================
# Source: k8s-terraform-master/Kubernetes Clusters/k8calab2/RemoteBuildFiles-calab/keepalived-dv1medk8lab2proxy1.conf
keepalived:
  virtual_router_id: 33        # line 12
  auth_pass: "supersecret1"    # line 20
  check_interval: 2            # line 3

  notification_email: "mark.deckert@medimpact.com"   
  notification_email_from: "kube-api-proxy@medimpact.com"  # k8s-terraform-master\Kubernetes Clusters\k8calab2\RemoteBuildFiles-calab\keepalived-dv1medk8lab2proxy1.conf line 37
  smtp_server: "mx.medimpact.com"
  smtp_connect_timeout: 30
  interface: "eth0"  # interface name (RHEL/CentOS 7): eth0, eth1, eth2 k8s-terraform-master\Kubernetes Clusters\k8calab2\RemoteBuildFiles-calab\keepalived-dv1medk8lab2proxy1.conf line 28


# ==============================================================================
# OIDC AUTHENTICATION CONFIGURATION
# ==============================================================================
oidc:
  enabled: true
  issuer_url: https://sts.medimpact.com/adfs  # Source: k8s-terraform-master/Kubernetes Clusters/k8calab2/RemoteBuildFiles-calab/kube/kube-master-config.yml (line 43)
  client_id: 916d15d5-65f1-481e-9b1a-819c17b8414b  # Source: k8s-terraform-master/Kubernetes Clusters/k8calab2/RemoteBuildFiles-calab/kube/kube-master-config.yml (line 41)
  username_claim: username  # Source: k8s-terraform-master/Kubernetes Clusters/k8calab2/RemoteBuildFiles-calab/kube/kube-master-config.yml (line 44)
  username_prefix: 'oidc:'  # Source: k8s-terraform-master/Kubernetes Clusters/k8calab2/RemoteBuildFiles-calab/kube/kube-master-config.yml (line 45)
  groups_claim: groups  # Source: k8s-terraform-master/Kubernetes Clusters/k8calab2/RemoteBuildFiles-calab/kube/kube-master-config.yml (line 42)


# ==============================================================================
# ADDITIONAL SERVICES
# ==============================================================================
# ⚠️ ENTIRE SECTION NOT IN OLD REPOS REPOS! 
# OLD REPOS deploys services manually using k8s-yamls-master repo ------------------------
# They don't have automated service deployment configuration
# These are YOUR automation's features, not OLD REPOS's old setup
services:
  deploy_ingress: true
  deploy_rbac: true
  deploy_metrics_server: true
  deploy_dashboard: false
  deploy_monitoring: false
  deploy_logging: false
  deploy_coredns: false  # done by kubespray itself
  deploy_test_app: false
  setup_maintenance: true
  ingress_class: "nginx"
  enable_external_ingress: false

# ==============================================================================
# ANSIBLE CONFIGURATION
# ==============================================================================
ansible:
  # Source: k8s-terraform-master/Kubernetes Clusters/k8calab2/kubecluster-clab2.tf (line 1)
  # variable "my_username" {default = "sa_mdeckert"}
  # ⚠️ This is vSphere username, NOT SSH username!
  # SSH user is likely "root" based on bootstrap scripts expecting root access
  user: "pv1medsysans2"  # ← ASK kiran TO CONFIRM!
  
  # ⚠️ NOT IN OLD REPOS REPOS - Need to ask Kiran for SSH key location
  ssh_private_key_file: "~/.ssh/id_rsa"  
  
  ssh_common_args: "-o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null"
  become: true
  become_method: "sudo"

# ==============================================================================
# SECURITY SETTINGS
# ==============================================================================
security:
  ssh_user: "pv1medsysans2"  # ← ask Kiran TO CONFIRM!
  ssh_key_path: "~/.ssh/id_rsa"  # ← ask Kiran!
  cert_validity_days: 365
  enable_rbac: true
  create_admin_user: true

# ==============================================================================
# SYSTEM CONFIGURATION
# ==============================================================================
system:
  enable_haproxy_sysctl: true
  haproxy_ip_nonlocal_bind: 1
  enable_system_upgrade: true
  system_upgrade_quiet: true

# ==============================================================================
# BACKUP CONFIGURATION
# ==============================================================================
# Source: k8s-terraform-master/Kubernetes Clusters/k8calab2/RemoteBuildFiles-calab/kube/backup-etcd.sh
# OLD REPOS HAS backup scripts, but no automation configuration 
# set to false as backup cronjob script needs to be converted
backup: 
  enabled: true  # ← OLD REPOS does backups manually via scripts
  retention_days: 7
  backup_path: "'/opt/app/etcd-backups"
  etcd_backup_enabled: true
  etcd_backup_schedule: "0 4 * * *"
  namespace_backup_enabled: true
  namespace_backup_schedule: "0 5 * * *"
  exclude_namespaces:
    - "kube-system"
    - "kube-public"

# ==============================================================================
# MAINTENANCE CONFIGURATION
# ==============================================================================
maintenance:
  # ETCD defragmentation schedule (cron format: minute hour day month weekday)
  etcd_defrag_schedule: "0 8 * * 0"  # Source: k8s-terraform-master/Kubernetes Clusters/k8calab2/RemoteBuildFiles-calab/kube/defrag-etcd.sh



# ==============================================================================
# MONITORING CONFIGURATION
# ==============================================================================
# ⚠️ ENTIRE SECTION NOT IN OLD REPOS REPOS!
# OLD REPOS deploys monitoring via k8s-yamls-master/All-Clusters-BASE-REQUIRED/monitoring/
# Not configured in infrastructure automation

# set to false as platform script are included
monitoring:
  enabled: false
  prometheus_enabled: false
  grafana_enabled: false
  alertmanager_enabled: false

# ==============================================================================
# STATUS
# ==============================================================================
status: "active"

