# ENVIRONMENT: k8calab2 (California Lab 2)
cluster_name: k8calab2
environment: dev
datacenter: WTD

# CLUSTER CONFIGURATION   
cluster:
  name: k8calab2
  container_runtime: containerd 
  domain: mednt

 
# VSPHERE CONFIGURATION
vsphere:
  server: "vcenter-wtd.medimpact.com" 
  datacenter: "WTD"
  datastore: "WTD_Datastore_01"
  resource_pool: "K8S_Resource_Pool"
  network: "vswitch2-med-vlan-33"
  template: "centos7"  

 
# NETWORK CONFIGURATION
network:
  prefix: "10.13.103"
  gateway: "10.13.103.1"
  netmask: "255.255.255.0"
  dns_servers:
    - "10.13.2.15"
    - "10.13.2.15"     
  domain: "cluster.local"  
  api_vip: "10.13.103.223"       
  ingress_vip: "10.13.103.223"   
  virtual_ip: "10.13.103.223"
  cni: "calico"
  service_cidr: "10.246.0.0/16" 
  pod_cidr: "10.246.0.0/16" 
  haproxy1_ip: "10.13.103.221"
  haproxy2_ip: "10.13.103.222"

 
# NODE DEFINITIONS
nodes:
  masters:
    - hostname: "dv1medk8lab2ma01"
      ip: "10.13.103.224"
      cpu: 2     
      memory: 8192 
      disk: 40
    
    - hostname: "dv1medk8lab2ma02"
      ip: "10.13.103.225"
      cpu: 2
      memory: 8192
      disk: 40
    
    - hostname: "dv1medk8lab2ma03"
      ip: "10.13.103.226"
      cpu: 2
      memory: 8192
      disk: 40
  
  workers:
    - hostname: "dv1medk8lab2no01"
      ip: "10.13.103.227"
      cpu: 2      
      memory: 10240 
      disk: 40    

    - hostname: "dv1medk8lab2no02"
      ip: "10.13.103.228"
      cpu: 2
      memory: 10240
      disk: 40

    - hostname: "dv1medk8lab2no03"
      ip: "10.13.103.229"
      cpu: 2
      memory: 10240
      disk: 40
    
    - hostname: "dv1medk8lab2no04"
      ip: "10.13.103.230"
      cpu: 2
      memory: 10240
      disk: 40
    
    - hostname: "dv1medk8lab2no05"
      ip: "10.13.103.231"
      cpu: 2
      memory: 10240
      disk: 40
  
  haproxy:
    - hostname: "dv1medk8lab2proxy1"
      ip: "10.13.103.221"
      cpu: 2        
      memory: 2048
      disk: 10
      keepalived_state: "MASTER"
      keepalived_priority: 200

    - hostname: "dv1medk8lab2proxy2"
      ip: "10.13.103.222"
      cpu: 2
      memory: 2048
      disk: 10
      keepalived_state: "BACKUP"    
      keepalived_priority: 100     

 
# HAPROXY CONFIGURATION
haproxy:
  maxconn: 4000
  timeout_connect: "10s"
  timeout_client: "1m"
  timeout_server: "1m"
  stats_port: 8080
  ingress_http_nodeport: 30080
  ingress_https_nodeport: 30443

 
# KEEPALIVED CONFIGURATION
keepalived:
  virtual_router_id: 33        
  auth_pass: "supersecret1"   
  check_interval: 2           

  notification_email: "mark.deckert@medimpact.com"   
  notification_email_from: "kube-api-proxy@medimpact.com"  
  smtp_server: "mx.medimpact.com"
  smtp_connect_timeout: 30
  interface: "eth0"  


# OIDC AUTHENTICATION CONFIGURATION
oidc:
  enabled: true
  issuer_url: https://sts.medimpact.com/adfs  
  client_id: 916d15d5-65f1-481e-9b1a-819c17b8414b  
  username_claim: username  
  username_prefix: 'oidc:'  
  groups_claim: groups 


 
# ADDITIONAL SERVICES
services:
  deploy_ingress: true
  deploy_rbac: true
  deploy_metrics_server: true
  deploy_dashboard: false
  deploy_monitoring: false
  deploy_logging: false
  deploy_coredns: false  
  deploy_test_app: false
  setup_maintenance: true
  ingress_class: "nginx"
  enable_external_ingress: false

 
# ANSIBLE CONFIGURATION
ansible:
  user: "pv1medsysans2" 
  ssh_private_key_file: "~/.ssh/id_rsa"  
  ssh_common_args: "-o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null"
  become: true
  become_method: "sudo"

 
# SECURITY SETTINGS
security:
  ssh_user: "pv1medsysans2"  
  ssh_key_path: "~/.ssh/id_rsa"
  cert_validity_days: 365
  enable_rbac: true
  create_admin_user: true

 
# SYSTEM CONFIGURATION
system:
  enable_haproxy_sysctl: true
  haproxy_ip_nonlocal_bind: 1
  enable_system_upgrade: true
  system_upgrade_quiet: true

# BACKUP CONFIGURATION
backup: 
  enabled: true  
  retention_days: 7
  backup_path: "/opt/app/etcd-backups"
  etcd_backup_enabled: true
  etcd_backup_schedule: "0 4 * * *"
  namespace_backup_enabled: true
  namespace_backup_schedule: "0 5 * * *"
  exclude_namespaces:
    - "kube-system"
    - "kube-public"

# MAINTENANCE CONFIGURATION
maintenance:
  etcd_defrag_schedule: "0 8 * * 0" 

# MONITORING CONFIGURATION
monitoring:
  enabled: false
  prometheus_enabled: false
  grafana_enabled: false
  alertmanager_enabled: false

# STATUS
status: "active"
