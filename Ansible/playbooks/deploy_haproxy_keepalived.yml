---
# ==============================================================================
# COMPLETE HAPROXY AND KEEPALIVED DEPLOYMENT PLAYBOOK
# ==============================================================================
# This playbook deploys HAProxy and keepalived with full automation
# Works dynamically for all environments
# Usage: ansible-playbook -i haproxy_inventory.ini deploy_haproxy_keepalived.yml
# ==============================================================================

- name: "=== COMPLETE HAPROXY AND KEEPALIVED DEPLOYMENT ==="
  hosts: haproxy
  gather_facts: true
  become: true
  vars:
    cluster_name: "{{ cluster_name | lower }}"
    # Health check and authentication
    keepalived_auth_pass: "{{ cluster_name }}123"
    haproxy_stats_port: "{{ haproxy.stats_port }}"
    
  tasks:
    # ==============================================================================
    # PHASE 1: SYSTEM PREPARATION - VALIDATE REQUIRED VARIABLES
    # ==============================================================================
    - name: Validate required variables from vars.yml
      assert:
        that:
          - cluster_name is defined
          - network is defined
          - network.virtual_ip is defined or network.api_vip is defined
          - haproxy is defined
          - haproxy.stats_port is defined
        fail_msg: "Required variables missing from vars.yml. Please ensure cluster_name, network.virtual_ip (or network.api_vip), and haproxy.stats_port are defined."
        success_msg: "All required variables are present"
      run_once: true

    - name: Set virtual IP from vars.yml
      set_fact:
        virtual_ip: "{{ network.virtual_ip | default(network.api_vip) }}"
      run_once: true

    - name: Display deployment information
      debug:
        msg:
          - "========================================="
          - "HAProxy and Keepalived Deployment"
          - "========================================="
          - "Cluster: {{ cluster_name | upper }}"
          - "Environment: {{ environment | default('') }}"
          - "Target Host: {{ inventory_hostname }} ({{ ansible_default_ipv4.address }})"
          - "Virtual IP: {{ virtual_ip }}"
          - "========================================="

    # ==============================================================================
    # PHASE 2: HAPROXY SYSCTL CONFIGURATION
    # ==============================================================================
    - name: Configure sysctl for HAProxy (ip_nonlocal_bind)
      sysctl:
        name: net.ipv4.ip_nonlocal_bind
        value: "{{ system.haproxy_ip_nonlocal_bind | default(1) | string }}"
        state: present
        sysctl_file: /etc/sysctl.d/haproxy.conf
        reload: yes
      when: system.enable_haproxy_sysctl | default(true) | bool

    # ==============================================================================
    # PHASE 3: SYSTEM UPDATE/UPGRADE
    # ==============================================================================
    - name: Yum upgrade (System upgrade)
      ansible.builtin.yum:
        name: "*"
        state: latest
        update_only: yes
        autoremove: yes
      when:
        - system.enable_system_upgrade | default(true) | bool
        - ansible_pkg_mgr == 'yum' or ansible_pkg_mgr == 'dnf'
      ignore_errors: yes
      async: 3600
      poll: 10

    - name: Install required packages
      package:
        name:
          - haproxy
          - keepalived
          - curl
          - net-tools
        state: present

    - name: Create HAProxy runtime directories
      file:
        path: "{{ item }}"
        state: directory
        owner: haproxy
        group: haproxy
        mode: '0755'
      loop:
        - /run/haproxy
        - /var/lib/haproxy

    # ==============================================================================
    # PHASE 4: KUBERNETES NODES DISCOVERY
    # ==============================================================================
    - name: Validate nodes configuration in vars.yml
      assert:
        that:
          - nodes is defined
          - nodes.masters is defined or network.master_ip is defined
          - nodes.workers is defined or (network.worker1_ip is defined and network.worker2_ip is defined)
        fail_msg: "Nodes configuration missing from vars.yml. Please define either nodes.masters/nodes.workers or network.master_ip/network.worker1_ip/network.worker2_ip"
        success_msg: "Nodes configuration validated"
      run_once: true

    # Get nodes from vars.yml - prefer nodes.masters/nodes.workers, fallback to network.*_ip
    - name: Get Kubernetes master nodes from vars.yml
      set_fact:
        k8s_masters: "{{ nodes.masters | map(attribute='ip') | list if (nodes.masters is defined) else [network.master_ip] }}"
      delegate_to: localhost
      run_once: true

    - name: Get Kubernetes worker nodes from vars.yml
      set_fact:
        k8s_workers: "{{ nodes.workers | map(attribute='ip') | list if (nodes.workers is defined) else [network.worker1_ip, network.worker2_ip] }}"
      delegate_to: localhost
      run_once: true

    - name: Validate discovered nodes are not empty
      assert:
        that:
          - k8s_masters is defined
          - k8s_masters | length > 0
          - k8s_workers is defined
          - k8s_workers | length > 0
        fail_msg: "Failed to discover Kubernetes nodes. Check vars.yml configuration."
        success_msg: "Kubernetes nodes discovered successfully"
      run_once: true

    - name: Display discovered Kubernetes nodes
      debug:
        msg:
          - "Master Nodes: {{ k8s_masters }}"
          - "Worker Nodes: {{ k8s_workers }}"

    # ==============================================================================
    # PHASE 5: HAPROXY CONFIGURATION
    # ==============================================================================
    - name: Create HAProxy configuration
      copy:
        content: |
          global
              log stdout local0
              chroot /var/lib/haproxy
              stats socket /run/haproxy/admin.sock mode 660 level admin
              stats timeout 30s
              user haproxy
              group haproxy
              daemon

          defaults
              mode http
              log global
              option httplog
              option dontlognull
              option log-health-checks
              option forwardfor except 127.0.0.0/8
              option redispatch
              retries 3
              timeout http-request {{ haproxy.timeout_connect | default('10s') }}
              timeout queue {{ haproxy.timeout_queue | default('1m') }}
              timeout connect {{ haproxy.timeout_connect | default('10s') }}
              timeout client {{ haproxy.timeout_client | default('1m') }}
              timeout server {{ haproxy.timeout_server | default('1m') }}
              timeout http-keep-alive {{ haproxy.timeout_http_keep_alive | default('10s') }}
              timeout check {{ haproxy.timeout_check | default('10s') }}
              maxconn {{ haproxy_maxconn_defaults }}

          # Kubernetes API Server Load Balancing
          frontend k8s_api_frontend
              bind *:6443
              mode tcp
              default_backend k8s_api_backend

          backend k8s_api_backend
              mode tcp
              balance roundrobin
              option tcp-check
          {% for master in k8s_masters %}
              server master{{ loop.index }} {{ master }}:6443 check
          {% endfor %}

          # Ingress HTTP Load Balancing  
          frontend ingress_http_frontend
              bind *:80
              default_backend ingress_http_backend

          backend ingress_http_backend
              balance roundrobin
              option httpchk GET /healthz
          {% for worker in k8s_workers %}
              server worker{{ loop.index }} {{ worker }}:30080 check
          {% endfor %}

          # Ingress HTTPS Load Balancing
          frontend ingress_https_frontend  
              bind *:443
              mode tcp
              default_backend ingress_https_backend

          backend ingress_https_backend
              mode tcp
              balance roundrobin
              option tcp-check
          {% for worker in k8s_workers %}
              server worker{{ loop.index }} {{ worker }}:30443 check
          {% endfor %}

          # HAProxy Stats
          frontend haproxy_stats
              bind *:{{ haproxy_stats_port }}
              stats enable
              stats uri /stats
              stats refresh 30s
              stats admin if TRUE
        dest: /etc/haproxy/haproxy.cfg
        owner: root
        group: root
        mode: '0644'
        backup: true
      notify: restart haproxy

    # ==============================================================================
    # PHASE 6: KEEPALIVED CONFIGURATION
    # ==============================================================================
    - name: Determine keepalived state and priority
      set_fact:
        keepalived_state: "{{ 'MASTER' if inventory_hostname == groups['haproxy'][0] else 'BACKUP' }}"
        keepalived_priority: "{{ 200 if inventory_hostname == groups['haproxy'][0] else 100 }}"

    - name: Generate keepalived configuration
      copy:
        content: |
          vrrp_script chk_haproxy {
              script "/bin/curl -f http://localhost:{{ haproxy_stats_port }}/stats || exit 1"
              interval {{ keepalived.check_interval | default(2) }}
              weight -2
              fall 3
              rise 2
          }

          vrrp_instance VI_1 {
              state {{ keepalived_state }}
              interface {{ keepalived.interface | default(ansible_default_ipv4.interface) }}
              virtual_router_id {{ keepalived.virtual_router_id | default(keepalived_virtual_router_id) }}
              priority {{ keepalived_priority }}
              advert_int 1
              smtp_alert

              unicast_src_ip {{ ansible_default_ipv4.address }}
              unicast_peer {
          {% for peer in groups['haproxy'] | difference([inventory_hostname]) %}
              {{ hostvars[peer].ansible_default_ipv4.address }}
          {% endfor %}
              }


              authentication {
                  auth_type PASS
                  auth_pass {{ keepalived.auth_pass | default(keepalived_auth_pass) }}
              }
              virtual_ipaddress {
                  {{ virtual_ip }} dev {{ keepalived.interface }}
              }
              track_script {
                  chk_haproxy
              }
          }

          global_defs {
              notification_email {
                  {{ keepalived.notification_email | default('mark.deckert@medimpact.com') }}
              }
              notification_email_from {{ keepalived.notification_from | default('kube-api-proxy@medimpact.com') }}
              smtp_server {{ keepalived.smtp_server | default('mx.medimpact.com') }}
              smtp_connect_timeout {{ keepalived.smtp_timeout | default(30) }}
          }


        dest: /etc/keepalived/keepalived.conf
        owner: root
        group: root
        mode: '0644'
        backup: true
      notify: restart keepalived

    # ==============================================================================
    # PHASE 7: SERVICE MANAGEMENT
    # ==============================================================================
    - name: Enable and start HAProxy
      systemd:
        name: haproxy
        enabled: true
        state: started
        daemon_reload: true

    - name: Enable and start keepalived
      systemd:
        name: keepalived
        enabled: true
        state: started
        daemon_reload: true

    - name: Wait for services to be fully started
      pause:
        seconds: 10

    # ==============================================================================
    # PHASE 8: VALIDATION
    # ==============================================================================
    - name: Check HAProxy service status
      systemd:
        name: haproxy
      register: haproxy_status

    - name: Check keepalived service status
      systemd:
        name: keepalived
      register: keepalived_status

    - name: Test HAProxy stats endpoint
      uri:
        url: "http://localhost:{{ haproxy_stats_port }}/stats"
        method: GET
        status_code: 200
      register: haproxy_stats_test
      retries: 5
      delay: 3
      ignore_errors: true

    - name: Test HAProxy health check endpoint
      uri:
        url: "http://localhost:{{ haproxy_health_check_port }}/healthz"
        method: GET
        status_code: 200
      register: haproxy_health_test
      retries: 5
      delay: 3
      ignore_errors: true
      when: haproxy_enable_health_check_endpoint | default(false)

    - name: Check virtual IP assignment
      shell: ip addr show {{ ansible_default_ipv4.interface }} | grep "{{ virtual_ip }}"
      register: vip_check
      failed_when: false
      changed_when: false

    - name: Display deployment results
      debug:
        msg:
          - "========================================="
          - "HAProxy and Keepalived Deployment Results"
          - "========================================="
          - "HAProxy Status: {{ 'Running' if haproxy_status.status.ActiveState == 'active' else 'Failed' }}"
          - "Keepalived Status: {{ 'Running' if keepalived_status.status.ActiveState == 'active' else 'Failed' }}"
          - "Stats Endpoint: {{ 'Accessible' if haproxy_stats_test.status == 200 else 'Failed' }}"
          - "Virtual IP: {{ 'Assigned' if vip_check.rc == 0 else 'Not Assigned' }} ({{ virtual_ip }})"
          - "Role: {{ keepalived_state }} (Priority: {{ keepalived_priority }})"
          - "========================================="
          - "Access Points:"
          - "- Kubernetes API: https://{{ virtual_ip }}:6443"
          - "- HTTP Ingress: http://{{ virtual_ip }}"
          - "- HTTPS Ingress: https://{{ virtual_ip }}"
          - "- HAProxy Stats: http://{{ virtual_ip }}:{{ haproxy_stats_port }}/stats"
          - "========================================="

  # ==============================================================================
  # HANDLERS
  # ==============================================================================
  handlers:
    - name: restart haproxy
      systemd:
        name: haproxy
        state: restarted
        daemon_reload: true

    - name: restart keepalived
      systemd:
        name: keepalived
        state: restarted
        daemon_reload: true
